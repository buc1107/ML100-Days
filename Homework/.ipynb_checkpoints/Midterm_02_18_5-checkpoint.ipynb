{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, metrics, linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_data = '../data/ml100marathon'\n",
    "train_app = os.path.join(dir_data, 'train_data.csv')\n",
    "test_app = os.path.join(dir_data, 'test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_app)\n",
    "#df_train.head()\n",
    "df_test = pd.read_csv(test_app)\n",
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 16)\n",
      "(33, 16)\n",
      "(146, 16)\n"
     ]
    }
   ],
   "source": [
    "df_train['deferred_income']*=-1\n",
    "df_test['deferred_income']*=-1\n",
    "df_train['restricted_stock_deferred']*=-1\n",
    "df_test['restricted_stock_deferred']*=-1\n",
    "train_Y = df_train['poi']\n",
    "test_name = df_test['name']\n",
    "#result_back = df_test[df_test['name']=='TOTAL']\n",
    "df_train_d = df_train.drop(['director_fees','loan_advances','name', 'email_address','restricted_stock_deferred','poi'] , axis=1)\n",
    "df_test_d = df_test.copy()\n",
    "#df_test_d[df_test_d['name'] == 'TOTAL'] = np.nan\n",
    "df_test_d = df_test_d.drop(['director_fees','loan_advances','name','restricted_stock_deferred','email_address'] , axis=1)\n",
    "#result_back_d = result_back.drop(['director_fees','loan_advances','name','restricted_stock_deferred','email_address'] , axis=1)\n",
    "\n",
    "print(df_train_d.values.shape)\n",
    "print(df_test_d.values.shape)\n",
    "df = pd.concat([df_train_d,df_test_d])\n",
    "print(df.values.shape)\n",
    "train_num = train_Y.shape[0]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_and_scale(in_df,fill_by,scale_by):\n",
    "    if fill_by == 'mean':\n",
    "        df1 = in_df.fillna(in_df.mean())\n",
    "    elif fill_by == 'median':\n",
    "        df1 = in_df.fillna(in_df.median())\n",
    "    elif fill_by == 'zero':\n",
    "        df1 = in_df.fillna(0)\n",
    "        \n",
    "    if scale_by == 'std':\n",
    "        df1 = StandardScaler().fit_transform(df1)\n",
    "    elif scale_by == 'minmax':\n",
    "        df1 = MinMaxScaler().fit_transform(df1)\n",
    "    return df1\n",
    "\n",
    "def run_and_predict(model,_train_X,_train_Y,_test_X,_test_Y):\n",
    "    model.fit(_train_X,_train_Y)\n",
    "    y_test_pred = model.predict(_test_X)\n",
    "    ascore = accuracy_score(y_test_pred,_test_Y)\n",
    "    prob_out = model.predict_proba(_test_X)[:,1];\n",
    "    print(\"prob_out.shape\",prob_out.shape)\n",
    "    print(\"_test_Y.shape\",_test_Y.shape)\n",
    "    aucscore = roc_auc_score(_test_Y,prob_out)\n",
    "    print(\"accuracy:\", ascore)\n",
    "    print(\"aucscore:\",aucscore)\n",
    "    return y_test_pred, prob_out, ascore, aucscore\n",
    "def write_prob (filename, _test_name, _y_prob):\n",
    "    y_pred_df = pd.DataFrame(data={'name':_test_name.values,'poi':_y_prob})\n",
    "    y_pred_df.to_csv(filename,index=None)\n",
    "def clip_outliers (in_df, col, th_low, th_high):\n",
    "    out_df = in_df.copy()\n",
    "    out_df[col] = in_df[col].clip(th_low,th_high)\n",
    "    return out_df\n",
    "def log1p (in_df, col):\n",
    "    out_df = in_df.copy()\n",
    "    out_df[col] = np.log1p(in_df[col])\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = fill_and_scale(df,'mean','std')\n",
    "estimator1 = LogisticRegression()\n",
    "df2 = fill_and_scale(df,'median','minmax')\n",
    "estimator2 = GradientBoostingClassifier()\n",
    "df3 = fill_and_scale(df,'median','minmax')\n",
    "estimator3 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882107843137\n",
      "0.883496732026\n",
      "0.918137254902\n",
      "X_train.shape =  (84, 16)\n",
      "X_test.shape =  (29, 16)\n",
      "y_train.shape =  (84,)\n",
      "y_test.shape =  (29,)\n"
     ]
    }
   ],
   "source": [
    "#split train and test \n",
    "train_X = df1[:train_num]\n",
    "test_X = df1[train_num:]\n",
    "train_X1, test_X1, train_Y1, test_Y1 = train_test_split(train_X,train_Y,test_size=0.25,random_state=118)\n",
    "print(cross_val_score(estimator1, train_X1, train_Y1, cv=5).mean())\n",
    "print(cross_val_score(estimator2, train_X1, train_Y1, cv=5).mean())\n",
    "print(cross_val_score(estimator3, train_X1, train_Y1, cv=5).mean())\n",
    "print(\"X_train.shape = \",train_X1.shape)\n",
    "print(\"X_test.shape = \",test_X1.shape)\n",
    "print(\"y_train.shape = \",train_Y1.shape)\n",
    "print(\"y_test.shape = \",test_Y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_out.shape (29,)\n",
      "_test_Y.shape (29,)\n",
      "accuracy: 0.931034482759\n",
      "aucscore: 0.388888888889\n",
      "prob_out.shape (29,)\n",
      "_test_Y.shape (29,)\n",
      "accuracy: 0.689655172414\n",
      "aucscore: 0.277777777778\n",
      "prob_out.shape (29,)\n",
      "_test_Y.shape (29,)\n",
      "accuracy: 0.862068965517\n",
      "aucscore: 0.592592592593\n"
     ]
    }
   ],
   "source": [
    "prob_out1, pred_out1, accu1, auc1 = run_and_predict(estimator1,train_X1, train_Y1, test_X1, test_Y1)\n",
    "outcome1 = estimator1.predict_proba(test_X)[:,1]\n",
    "\n",
    "prob_out2, pred_out2, accu2, auc2 = run_and_predict(estimator2,train_X1, train_Y1, test_X1, test_Y1)\n",
    "outcome2 = estimator2.predict_proba(test_X)[:,1]\n",
    "\n",
    "prob_out3, pred_out3, accu3, auc3 = run_and_predict(estimator3,train_X1, train_Y1, test_X1, test_Y1)\n",
    "outcome3 = estimator3.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37037037037\n"
     ]
    }
   ],
   "source": [
    "prob_out = (prob_out1*0.73+prob_out2*0.83+prob_out3*0.67)/(0.73+0.83+0.67)\n",
    "aucout = roc_auc_score(test_Y1,prob_out)\n",
    "print(aucout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32000286,  0.1476849 ,  0.28623662,  0.12338059,  0.19930283,\n",
       "        0.16333632,  0.58272571,  0.13370174,  0.08529486,  0.10853468,\n",
       "        0.13564484,  0.15036349,  0.13871193,  0.13394383,  0.19922134,\n",
       "        0.13895956,  0.10640126,  0.11315506,  0.10746148,  0.09938178,\n",
       "        1.        ,  0.19447384,  0.16479864,  0.16284755,  0.1310931 ,\n",
       "        0.13915429,  0.17311455,  0.10497622,  0.17275299,  0.20414885,\n",
       "        0.12172335,  0.11727173,  0.22661347])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.64717211e-01,   9.85930026e-01,   9.78442710e-01,\n",
       "         7.83316319e-04,   1.12513862e-03,   7.87616114e-03,\n",
       "         9.99160993e-01,   5.76371544e-03,   9.52699162e-04,\n",
       "         6.83939822e-03,   1.12513862e-03,   4.69398252e-04,\n",
       "         2.35545354e-03,   4.78339988e-03,   9.87652205e-01,\n",
       "         4.69398252e-04,   2.22662381e-03,   1.03671952e-02,\n",
       "         8.79174423e-01,   6.45313531e-04,   9.95162244e-01,\n",
       "         1.12513862e-03,   7.87948391e-04,   1.04842388e-03,\n",
       "         1.04754793e-03,   3.25308019e-03,   7.70080887e-04,\n",
       "         9.27154457e-04,   3.53682767e-03,   1.83888653e-03,\n",
       "         7.88607438e-04,   3.89139538e-03,   1.13295893e-02])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3,  0.5,  0.6,  0.1,  0.1,  0.4,  0.6,  0.1,  0. ,  0.2,  0. ,\n",
       "        0. ,  0. ,  0. ,  0.5,  0. ,  0.3,  0.3,  0.5,  0. ,  1. ,  0.2,\n",
       "        0. ,  0.1,  0.2,  0.3,  0.1,  0.1,  0.2,  0.2,  0. ,  0.1,  0.1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome = (outcome1*0.72875+outcome2*0.83571)/(0.72875+0.83571)\n",
    "pirnt(roc_auc_score(_test_Y,outocme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outcome)\n",
    "print(outcome.shape)\n",
    "write_prob('02_18_5.csv',test_name,outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = log1p(df,'bonus')\n",
    "# df = log1p(df,'deferral_payments')\n",
    "# df = log1p(df,'deferred_income')\n",
    "# df = log1p(df,'exercised_stock_options')\n",
    "# df = log1p(df,'expenses')\n",
    "# df = log1p(df,'long_term_incentive')\n",
    "# df = log1p(df,'restricted_stock')\n",
    "# df = log1p(df,'salary')\n",
    "# df = log1p(df,'shared_receipt_with_poi')\n",
    "# df = log1p(df,'to_messages')\n",
    "# df = log1p(df,'total_payments')\n",
    "# df = log1p(df,'total_stock_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all_corr = df.corr()\n",
    "# all_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig_num = 16\n",
    "# plt.figure(figsize=(20,fig_num*3))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "# index = 1\n",
    "# for col in df:\n",
    "#     plt.subplot(fig_num,1,index)\n",
    "#     plt.title(\"distribution of \"+col)\n",
    "#     sns.distplot(df[col].dropna())\n",
    "#     index += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# heatmap = sns.heatmap(all_corr, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #import seaborn as sns\n",
    "# fig_num = 8*15 \n",
    "# plt.figure(figsize=(20,fig_num*3))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "# index = 1\n",
    "# for i in range(len(list(df))):\n",
    "#     for j in range(len(list(df))):\n",
    "#         if j > i:\n",
    "#             plt.subplot(fig_num,1,index)\n",
    "#             plt.title(list(df)[i]+' vs '+list(df)[j]+' corr = '+str(all_corr.iloc[i,j]))\n",
    "#             #sns.kdeplot(df.iloc[:,i],df.iloc[:,j])\n",
    "#             plt.plot(df.iloc[:,i],df.iloc[:,j],'.')\n",
    "#             index += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df1 = df.fillna(df.mean())\n",
    "# df_temp = MinMaxScaler().fit_transform(df1)\n",
    "# train_X = df_temp[:train_num]\n",
    "# test_X = df_temp[train_num:]\n",
    "# estimator = GradientBoostingClassifier()\n",
    "# print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "# estimator.fit(train_X,train_Y)\n",
    "# y_hat = estimator.predict(test_X)\n",
    "# #print(test_X)\n",
    "# print(y_hat)\n",
    "# y_prob2 = estimator.predict_proba(test_X)[:,1]\n",
    "# print(y_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df1 = df.fillna(df.mean())\n",
    "# df_temp = StandardScaler().fit_transform(df1)\n",
    "# train_X = df_temp[:train_num]\n",
    "# test_X = df_temp[train_num:]\n",
    "# estimator = RandomForestClassifier()\n",
    "# print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "# estimator.fit(train_X,train_Y)\n",
    "# y_hat = estimator.predict(test_X)\n",
    "# #print(test_X)\n",
    "# print(y_hat)\n",
    "# y_prob3 = estimator.predict_proba(test_X)[:,1]\n",
    "# print(y_prob3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# vocabulary\n",
    "* repayment: 貸款的還款\n",
    "* loan advances: 貸款預付款\n",
    "* promissory note: 本票\n",
    "* severance: 遣散"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
