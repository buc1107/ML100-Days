{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, metrics, linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_data = '../data/ml100marathon'\n",
    "train_app = os.path.join(dir_data, 'train_data.csv')\n",
    "test_app = os.path.join(dir_data, 'test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_app)\n",
    "#df_train.head()\n",
    "df_test = pd.read_csv(test_app)\n",
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 16)\n",
      "(33, 16)\n",
      "(146, 16)\n"
     ]
    }
   ],
   "source": [
    "df_train['deferred_income']*=-1\n",
    "df_test['deferred_income']*=-1\n",
    "df_train['restricted_stock_deferred']*=-1\n",
    "df_test['restricted_stock_deferred']*=-1\n",
    "train_Y = df_train['poi']\n",
    "test_name = df_test['name']\n",
    "#result_back = df_test[df_test['name']=='TOTAL']\n",
    "df_train_d = df_train.drop(['director_fees','loan_advances','name', 'email_address','restricted_stock_deferred','poi'] , axis=1)\n",
    "df_test_d = df_test.copy()\n",
    "#df_test_d[df_test_d['name'] == 'TOTAL'] = np.nan\n",
    "df_test_d = df_test_d.drop(['director_fees','loan_advances','name','restricted_stock_deferred','email_address'] , axis=1)\n",
    "#result_back_d = result_back.drop(['director_fees','loan_advances','name','restricted_stock_deferred','email_address'] , axis=1)\n",
    "\n",
    "print(df_train_d.values.shape)\n",
    "print(df_test_d.values.shape)\n",
    "df = pd.concat([df_train_d,df_test_d])\n",
    "print(df.values.shape)\n",
    "train_num = train_Y.shape[0]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_and_scale(in_df,fill_by,scale_by):\n",
    "    if fill_by == 'mean':\n",
    "        df1 = in_df.fillna(in_df.mean())\n",
    "    elif fill_by == 'median':\n",
    "        df1 = in_df.fillna(in_df.median())\n",
    "    elif fill_by == 'zero':\n",
    "        df1 = in_df.fillna(0)\n",
    "        \n",
    "    if scale_by == 'std':\n",
    "        df1 = StandardScaler().fit_transform(df1)\n",
    "    elif scale_by == 'minmax':\n",
    "        df1 = MinMaxScaler().fit_transform(df1)\n",
    "    return df1\n",
    "\n",
    "def run_and_predict(model,_train_X,_train_Y,_test_X,_test_Y):\n",
    "    model.fit(_train_X,_train_Y)\n",
    "    y_test_pred = model.predict(_test_X)\n",
    "    ascore = accuracy_score(y_test_pred,_test_Y)\n",
    "    prob_out = model.predict_proba(_test_X)[:,1];\n",
    "    print(\"prob_out.shape\",prob_out.shape)\n",
    "    print(\"_test_Y.shape\",_test_Y.shape)\n",
    "    aucscore = roc_auc_score(_test_Y,prob_out)\n",
    "    print(\"accuracy:\", ascore)\n",
    "    print(\"aucscore:\",aucscore)\n",
    "    return y_test_pred, prob_out, ascore, aucscore\n",
    "def write_prob (filename, _test_name, _y_prob):\n",
    "    y_pred_df = pd.DataFrame(data={'name':_test_name.values,'poi':_y_prob})\n",
    "    y_pred_df.to_csv(filename,index=None)\n",
    "def clip_outliers (in_df, col, th_low, th_high):\n",
    "    out_df = in_df.copy()\n",
    "    out_df[col] = in_df[col].clip(th_low,th_high)\n",
    "    return out_df\n",
    "def log1p (in_df, col):\n",
    "    out_df = in_df.copy()\n",
    "    out_df[col] = np.log1p(in_df[col])\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = fill_and_scale(df,'mean','std')\n",
    "estimator1 = LogisticRegression()\n",
    "df2 = fill_and_scale(df,'median','minmax')\n",
    "estimator2 = GradientBoostingClassifier()\n",
    "df3 = fill_and_scale(df,'median','minmax')\n",
    "estimator3 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869852941176\n",
      "0.893382352941\n",
      "X_train.shape =  (84, 16)\n",
      "X_test.shape =  (29, 16)\n",
      "y_train.shape =  (84,)\n",
      "y_test.shape =  (29,)\n"
     ]
    }
   ],
   "source": [
    "#split train and test \n",
    "train_X = df1[:train_num]\n",
    "test_X = df1[train_num:]\n",
    "train_X1, test_X1, train_Y1, test_Y1 = train_test_split(train_X,train_Y,test_size=0.25,random_state=48)\n",
    "print(cross_val_score(estimator1, train_X1, train_Y1, cv=5).mean())\n",
    "print(cross_val_score(estimator2, train_X1, train_Y1, cv=5).mean())\n",
    "print(cross_val_score(estimator3, train_X1, train_Y1, cv=5).mean())\n",
    "print(\"X_train.shape = \",train_X1.shape)\n",
    "print(\"X_test.shape = \",test_X1.shape)\n",
    "print(\"y_train.shape = \",train_Y1.shape)\n",
    "print(\"y_test.shape = \",test_Y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_out.shape (29,)\n",
      "_test_Y.shape (29,)\n",
      "accuracy: 0.896551724138\n",
      "aucscore: 0.79\n",
      "prob_out.shape (29,)\n",
      "_test_Y.shape (29,)\n",
      "accuracy: 0.862068965517\n",
      "aucscore: 0.865\n"
     ]
    }
   ],
   "source": [
    "prob_out1, pred_out1, accu1, auc1 = run_and_predict(estimator1,train_X1, train_Y1, test_X1, test_Y1)\n",
    "outcome1 = estimator1.predict_proba(test_X)[:,1]\n",
    "\n",
    "prob_out2, pred_out2, accu2, auc2 = run_and_predict(estimator2,train_X1, train_Y1, test_X1, test_Y1)\n",
    "outcome2 = estimator2.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "prob_out = (prob_out1*0.72875+prob_out2*0.83571)/(0.72875+0.83571)\n",
    "aucout = roc_auc_score(test_Y1,prob_out)\n",
    "print(aucout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44329017,  0.23369275,  0.18946494,  0.01967682,  0.16357818,\n",
       "        0.13007691,  0.75320833,  0.11769373,  0.23399485,  0.08702239,\n",
       "        0.10957935,  0.1039527 ,  0.11612666,  0.11881007,  0.15747197,\n",
       "        0.09524761,  0.09100527,  0.10516589,  0.09674904,  0.0919729 ,\n",
       "        1.        ,  0.13322058,  0.1379518 ,  0.14201427,  0.11600742,\n",
       "        0.10540028,  0.10655495,  0.09493193,  0.11114004,  0.11920474,\n",
       "        0.07948757,  0.09505753,  0.17205611])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.71100111e-02,   1.94449556e-01,   3.96111226e-03,\n",
       "         8.16047875e-04,   5.93827925e-03,   4.97574829e-03,\n",
       "         9.93923623e-01,   2.68703131e-03,   1.09473025e-03,\n",
       "         1.27002627e-03,   8.84147571e-04,   8.84147571e-04,\n",
       "         7.38291427e-04,   1.09455859e-03,   2.03662439e-01,\n",
       "         1.26133605e-03,   5.75371340e-04,   2.83389628e-02,\n",
       "         2.68244940e-02,   3.50063610e-04,   9.98020434e-01,\n",
       "         1.35157691e-03,   8.87584260e-04,   8.18708454e-04,\n",
       "         8.87584260e-04,   1.68828608e-03,   7.38291427e-04,\n",
       "         4.19254020e-04,   1.21489823e-03,   3.47677595e-03,\n",
       "         4.19254020e-04,   6.67559485e-04,   7.22052521e-01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome = (outcome1*0.72875+outcome2*0.83571)/(0.72875+0.83571)\n",
    "pirnt(roc_auc_score(_test_Y,outocme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21279905  0.37726279  0.09194001  0.00965499  0.083927    0.0645733\n",
      "  0.88108025  0.05725974  0.10942076  0.04103582  0.05146723  0.04884625\n",
      "  0.05445862  0.05580981  0.10441938  0.04513235  0.04272434  0.07518564\n",
      "  0.07588904  0.04307027  0.98865998  0.06257182  0.06486494  0.06663317\n",
      "  0.0546429   0.0498844   0.04999997  0.04448514  0.05252114  0.05761752\n",
      "  0.03729091  0.04466292  0.39997819]\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "print(outcome)\n",
    "print(outcome.shape)\n",
    "write_prob('02_18_4.csv',test_name,outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = log1p(df,'bonus')\n",
    "# df = log1p(df,'deferral_payments')\n",
    "# df = log1p(df,'deferred_income')\n",
    "# df = log1p(df,'exercised_stock_options')\n",
    "# df = log1p(df,'expenses')\n",
    "# df = log1p(df,'long_term_incentive')\n",
    "# df = log1p(df,'restricted_stock')\n",
    "# df = log1p(df,'salary')\n",
    "# df = log1p(df,'shared_receipt_with_poi')\n",
    "# df = log1p(df,'to_messages')\n",
    "# df = log1p(df,'total_payments')\n",
    "# df = log1p(df,'total_stock_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all_corr = df.corr()\n",
    "# all_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig_num = 16\n",
    "# plt.figure(figsize=(20,fig_num*3))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "# index = 1\n",
    "# for col in df:\n",
    "#     plt.subplot(fig_num,1,index)\n",
    "#     plt.title(\"distribution of \"+col)\n",
    "#     sns.distplot(df[col].dropna())\n",
    "#     index += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# heatmap = sns.heatmap(all_corr, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #import seaborn as sns\n",
    "# fig_num = 8*15 \n",
    "# plt.figure(figsize=(20,fig_num*3))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "# index = 1\n",
    "# for i in range(len(list(df))):\n",
    "#     for j in range(len(list(df))):\n",
    "#         if j > i:\n",
    "#             plt.subplot(fig_num,1,index)\n",
    "#             plt.title(list(df)[i]+' vs '+list(df)[j]+' corr = '+str(all_corr.iloc[i,j]))\n",
    "#             #sns.kdeplot(df.iloc[:,i],df.iloc[:,j])\n",
    "#             plt.plot(df.iloc[:,i],df.iloc[:,j],'.')\n",
    "#             index += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df1 = df.fillna(df.mean())\n",
    "# df_temp = MinMaxScaler().fit_transform(df1)\n",
    "# train_X = df_temp[:train_num]\n",
    "# test_X = df_temp[train_num:]\n",
    "# estimator = GradientBoostingClassifier()\n",
    "# print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "# estimator.fit(train_X,train_Y)\n",
    "# y_hat = estimator.predict(test_X)\n",
    "# #print(test_X)\n",
    "# print(y_hat)\n",
    "# y_prob2 = estimator.predict_proba(test_X)[:,1]\n",
    "# print(y_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df1 = df.fillna(df.mean())\n",
    "# df_temp = StandardScaler().fit_transform(df1)\n",
    "# train_X = df_temp[:train_num]\n",
    "# test_X = df_temp[train_num:]\n",
    "# estimator = RandomForestClassifier()\n",
    "# print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "# estimator.fit(train_X,train_Y)\n",
    "# y_hat = estimator.predict(test_X)\n",
    "# #print(test_X)\n",
    "# print(y_hat)\n",
    "# y_prob3 = estimator.predict_proba(test_X)[:,1]\n",
    "# print(y_prob3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# vocabulary\n",
    "* repayment: 貸款的還款\n",
    "* loan advances: 貸款預付款\n",
    "* promissory note: 本票\n",
    "* severance: 遣散"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
