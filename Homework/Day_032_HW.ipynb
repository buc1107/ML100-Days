{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "相信大家目前都能夠初步了解機器學習專案的流程及步驟，今天的作業希望大家能夠看看全球機器學習巨頭們在做的機器學習專案。以 google 為例，下圖是 Google 內部專案使用機器學習的數量，隨著時間進展，現在早已超過 2000 個專案在使用 ML。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*U_L8qI8RmYS-MOBrYvXhSA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "底下幫同學整理幾間知名企業的 blog 或機器學習網站 (自行搜尋也可)，請挑選一篇文章閱讀並試著回答\n",
    "1. 專案的目標？ (要解決什麼問題）\n",
    "2. 使用的技術是？ (只需知道名稱即可，例如：使用 CNN 卷積神經網路做影像分類)\n",
    "3. 資料來源？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Google AI blog](https://ai.googleblog.com/)\n",
    "- [Facebook Research blog](https://research.fb.com/blog/)\n",
    "- [Apple machine learning journal](https://machinelearning.apple.com/)\n",
    "- [機器之心](https://www.jiqizhixin.com/)\n",
    "- [雷鋒網](http://www.leiphone.com/category/ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 閱讀文章\n",
    "Soft Actor-Critic: Deep Reinforcement Learning for Robotics (Google AI Blog)\n",
    "\n",
    "## 專案的目標\n",
    "學習機器人在應對真實世界中的複雜動作，真實世界的環境是多變的，SAC能直接從環境中學習，並適應環境的變化\n",
    "\n",
    "## 使用的技術\n",
    "Deed reinforcement learning based on maximum entropy framework\n",
    "\n",
    "## 資料來源\n",
    "與真實環境互動，並透過最大化entropy的reward機制,從隨機策略中學習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
