{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, metrics, linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_data = '../data/ml100marathon'\n",
    "train_app = os.path.join(dir_data, 'train_data.csv')\n",
    "test_app = os.path.join(dir_data, 'test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_app)\n",
    "#df_train.head()\n",
    "df_test = pd.read_csv(test_app)\n",
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 16)\n",
      "(33, 16)\n",
      "(146, 16)\n"
     ]
    }
   ],
   "source": [
    "df_train['deferred_income']*=-1\n",
    "df_test['deferred_income']*=-1\n",
    "df_train['restricted_stock_deferred']*=-1\n",
    "df_test['restricted_stock_deferred']*=-1\n",
    "train_Y = df_train['poi']\n",
    "test_name = df_test['name']\n",
    "#result_back = df_test[df_test['name']=='TOTAL']\n",
    "df_train_d = df_train.drop(['director_fees','loan_advances','name', 'email_address','restricted_stock_deferred','poi'] , axis=1)\n",
    "df_test_d = df_test.copy()\n",
    "#df_test_d[df_test_d['name'] == 'TOTAL'] = np.nan\n",
    "df_test_d = df_test_d.drop(['director_fees','loan_advances','name','restricted_stock_deferred','email_address'] , axis=1)\n",
    "#result_back_d = result_back.drop(['director_fees','loan_advances','name','restricted_stock_deferred','email_address'] , axis=1)\n",
    "\n",
    "print(df_train_d.values.shape)\n",
    "print(df_test_d.values.shape)\n",
    "df = pd.concat([df_train_d,df_test_d])\n",
    "print(df.values.shape)\n",
    "train_num = train_Y.shape[0]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_and_scale(in_df,fill_by,scale_by):\n",
    "    if fill_by == 'mean':\n",
    "        df1 = in_df.fillna(in_df.mean())\n",
    "    elif fill_by == 'median':\n",
    "        df1 = in_df.fillna(in_df.median())\n",
    "    elif fill_by == 'zero':\n",
    "        df1 = in_df.fillna(0)\n",
    "        \n",
    "    if scale_by == 'std':\n",
    "        df1 = StandardScaler().fit_transform(df1)\n",
    "    elif scale_by == 'minmax':\n",
    "        df1 = MinMaxScaler().fit_transform(df1)\n",
    "    return df1\n",
    "\n",
    "def run_and_predict(model,_train_X,_train_Y,_test_X,_test_Y):\n",
    "    model.fit(_train_X,_train_Y)\n",
    "    y_test_pred = model.predict(_test_X)\n",
    "    ascore = accuracy_score(y_test_pred,_test_Y)\n",
    "    prob_out = model.predict_proba(_test_X)[:,1];\n",
    "    print(\"prob_out.shape\",prob_out.shape)\n",
    "    print(\"_test_Y.shape\",_test_Y.shape)\n",
    "    aucscore = roc_auc_score(_test_Y,prob_out)\n",
    "    print(\"accuracy:\", ascore)\n",
    "    print(\"aucscore:\",aucscore)\n",
    "    return y_test_pred, prob_out, ascore, aucscore\n",
    "def write_prob (filename, _test_name, _y_prob):\n",
    "    y_pred_df = pd.DataFrame(data={'name':_test_name.values,'poi':_y_prob})\n",
    "    y_pred_df.to_csv(filename,index=None)\n",
    "def clip_outliers (in_df, col, th_low, th_high):\n",
    "    out_df = in_df.copy()\n",
    "    out_df[col] = in_df[col].clip(th_low,th_high)\n",
    "    return out_df\n",
    "def log1p (in_df, col):\n",
    "    out_df = in_df.copy()\n",
    "    out_df[col] = np.log1p(in_df[col])\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = fill_and_scale(df,'mean','std')\n",
    "estimator1 = LogisticRegression()\n",
    "df2 = fill_and_scale(df,'median','minmax')\n",
    "estimator2 = GradientBoostingClassifier()\n",
    "df3 = fill_and_scale(df,'median','minmax')\n",
    "estimator3 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869852941176\n",
      "0.869852941176\n",
      "0.905882352941\n",
      "X_train.shape =  (84, 16)\n",
      "X_test.shape =  (29, 16)\n",
      "y_train.shape =  (84,)\n",
      "y_test.shape =  (29,)\n"
     ]
    }
   ],
   "source": [
    "#split train and test \n",
    "train_X = df1[:train_num]\n",
    "test_X = df1[train_num:]\n",
    "train_X1, test_X1, train_Y1, test_Y1 = train_test_split(train_X,train_Y,test_size=0.25,random_state=48)\n",
    "print(cross_val_score(estimator1, train_X1, train_Y1, cv=5).mean())\n",
    "print(cross_val_score(estimator2, train_X1, train_Y1, cv=5).mean())\n",
    "print(cross_val_score(estimator3, train_X1, train_Y1, cv=5).mean())\n",
    "print(\"X_train.shape = \",train_X1.shape)\n",
    "print(\"X_test.shape = \",test_X1.shape)\n",
    "print(\"y_train.shape = \",train_Y1.shape)\n",
    "print(\"y_test.shape = \",test_Y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_out.shape (29,)\n",
      "_test_Y.shape (29,)\n",
      "accuracy: 0.896551724138\n",
      "aucscore: 0.79\n",
      "prob_out.shape (29,)\n",
      "_test_Y.shape (29,)\n",
      "accuracy: 0.896551724138\n",
      "aucscore: 0.845\n",
      "prob_out.shape (29,)\n",
      "_test_Y.shape (29,)\n",
      "accuracy: 0.896551724138\n",
      "aucscore: 0.94\n"
     ]
    }
   ],
   "source": [
    "prob_out1, pred_out1, accu1, auc1 = run_and_predict(estimator1,train_X1, train_Y1, test_X1, test_Y1)\n",
    "outcome1 = estimator1.predict_proba(test_X)[:,1]\n",
    "\n",
    "prob_out2, pred_out2, accu2, auc2 = run_and_predict(estimator2,train_X1, train_Y1, test_X1, test_Y1)\n",
    "outcome2 = estimator2.predict_proba(test_X)[:,1]\n",
    "\n",
    "prob_out3, pred_out3, accu3, auc3 = run_and_predict(estimator3,train_X1, train_Y1, test_X1, test_Y1)\n",
    "outcome3 = estimator3.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735\n"
     ]
    }
   ],
   "source": [
    "prob_out = (prob_out1*0.73+prob_out2*0.83+prob_out3*0.67)/(0.73+0.83+0.67)\n",
    "aucout = roc_auc_score(test_Y1,prob_out)\n",
    "print(aucout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44329017,  0.23369275,  0.18946494,  0.01967682,  0.16357818,\n",
       "        0.13007691,  0.75320833,  0.11769373,  0.23399485,  0.08702239,\n",
       "        0.10957935,  0.1039527 ,  0.11612666,  0.11881007,  0.15747197,\n",
       "        0.09524761,  0.09100527,  0.10516589,  0.09674904,  0.0919729 ,\n",
       "        1.        ,  0.13322058,  0.1379518 ,  0.14201427,  0.11600742,\n",
       "        0.10540028,  0.10655495,  0.09493193,  0.11114004,  0.11920474,\n",
       "        0.07948757,  0.09505753,  0.17205611])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.80192195e-03,   3.77242185e-01,   1.56484148e-02,\n",
       "         9.15835408e-04,   1.44701428e-02,   7.45328885e-03,\n",
       "         9.97845348e-01,   4.56050908e-03,   7.90540360e-04,\n",
       "         9.34935528e-04,   7.92702325e-04,   7.92702325e-04,\n",
       "         6.83282315e-04,   8.72763241e-04,   1.16797721e-01,\n",
       "         1.43119386e-03,   6.22731872e-04,   1.20162244e-01,\n",
       "         1.39515626e-01,   4.26549878e-04,   9.91682883e-01,\n",
       "         9.65172746e-04,   1.13224515e-03,   8.99875607e-04,\n",
       "         1.13224515e-03,   1.47382447e-03,   6.83282315e-04,\n",
       "         4.94877423e-04,   1.40469476e-03,   3.91266798e-03,\n",
       "         4.94877423e-04,   7.18161392e-04,   3.60596486e-01])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3,  0.5,  0.6,  0.1,  0.1,  0.4,  0.6,  0.1,  0. ,  0.2,  0. ,\n",
       "        0. ,  0. ,  0. ,  0.5,  0. ,  0.3,  0.3,  0.5,  0. ,  1. ,  0.2,\n",
       "        0. ,  0.1,  0.2,  0.3,  0.1,  0.1,  0.2,  0.2,  0. ,  0.1,  0.1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = (outcome1*0.73+outcome2*0.83+outcome3*0.67)/(0.73+0.83+0.67)\n",
    "#print(roc_auc_score(test_Y1,outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17843382  0.27699853  0.15798098  0.06687185  0.0889786   0.04535533\n",
      "  0.73814068  0.04022495  0.07689345  0.05887997  0.096256    0.0343244\n",
      "  0.03826887  0.03921782  0.18515545  0.0317124   0.03002274  0.16928509\n",
      "  0.20377792  0.03026648  0.87672502  0.04396956  0.04558053  0.07686875\n",
      "  0.03839694  0.03505179  0.03513553  0.03126056  0.03690499  0.10056815\n",
      "  0.02620479  0.06142963  0.31071571]\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "print(outcome)\n",
    "print(outcome.shape)\n",
    "write_prob('02_18_5.csv',test_name,outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = log1p(df,'bonus')\n",
    "# df = log1p(df,'deferral_payments')\n",
    "# df = log1p(df,'deferred_income')\n",
    "# df = log1p(df,'exercised_stock_options')\n",
    "# df = log1p(df,'expenses')\n",
    "# df = log1p(df,'long_term_incentive')\n",
    "# df = log1p(df,'restricted_stock')\n",
    "# df = log1p(df,'salary')\n",
    "# df = log1p(df,'shared_receipt_with_poi')\n",
    "# df = log1p(df,'to_messages')\n",
    "# df = log1p(df,'total_payments')\n",
    "# df = log1p(df,'total_stock_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all_corr = df.corr()\n",
    "# all_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig_num = 16\n",
    "# plt.figure(figsize=(20,fig_num*3))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "# index = 1\n",
    "# for col in df:\n",
    "#     plt.subplot(fig_num,1,index)\n",
    "#     plt.title(\"distribution of \"+col)\n",
    "#     sns.distplot(df[col].dropna())\n",
    "#     index += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# heatmap = sns.heatmap(all_corr, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #import seaborn as sns\n",
    "# fig_num = 8*15 \n",
    "# plt.figure(figsize=(20,fig_num*3))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "# index = 1\n",
    "# for i in range(len(list(df))):\n",
    "#     for j in range(len(list(df))):\n",
    "#         if j > i:\n",
    "#             plt.subplot(fig_num,1,index)\n",
    "#             plt.title(list(df)[i]+' vs '+list(df)[j]+' corr = '+str(all_corr.iloc[i,j]))\n",
    "#             #sns.kdeplot(df.iloc[:,i],df.iloc[:,j])\n",
    "#             plt.plot(df.iloc[:,i],df.iloc[:,j],'.')\n",
    "#             index += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df1 = df.fillna(df.mean())\n",
    "# df_temp = MinMaxScaler().fit_transform(df1)\n",
    "# train_X = df_temp[:train_num]\n",
    "# test_X = df_temp[train_num:]\n",
    "# estimator = GradientBoostingClassifier()\n",
    "# print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "# estimator.fit(train_X,train_Y)\n",
    "# y_hat = estimator.predict(test_X)\n",
    "# #print(test_X)\n",
    "# print(y_hat)\n",
    "# y_prob2 = estimator.predict_proba(test_X)[:,1]\n",
    "# print(y_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df1 = df.fillna(df.mean())\n",
    "# df_temp = StandardScaler().fit_transform(df1)\n",
    "# train_X = df_temp[:train_num]\n",
    "# test_X = df_temp[train_num:]\n",
    "# estimator = RandomForestClassifier()\n",
    "# print(cross_val_score(estimator, train_X, train_Y, cv=5).mean())\n",
    "# estimator.fit(train_X,train_Y)\n",
    "# y_hat = estimator.predict(test_X)\n",
    "# #print(test_X)\n",
    "# print(y_hat)\n",
    "# y_prob3 = estimator.predict_proba(test_X)[:,1]\n",
    "# print(y_prob3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# vocabulary\n",
    "* repayment: 貸款的還款\n",
    "* loan advances: 貸款預付款\n",
    "* promissory note: 本票\n",
    "* severance: 遣散"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
